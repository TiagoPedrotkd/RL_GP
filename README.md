
# ðŸ¤– Reinforcement Learning Project

This repository contains the implementation of a Reinforcement Learning (RL) project developed as part of the RL course. The goal is to train and compare multiple RL agents on two distinct environments from the [Gymnasium](https://gymnasium.farama.org/) library, focusing on performance, convergence, and the trade-off between exploration and exploitation.

---

## ðŸ“Œ Objectives

- Solve **two different Gymnasium environments** using different RL algorithms.
- Compare the performance of algorithms such as Q-Learning, SARSA, Monte Carlo, and PPO.
- Visualize learning progress with reward curves, success rates, and convergence plots.
- Analyze agent behavior and interpret learned policies.

---

## ðŸ§± Project Structure

```
RL_GP/
â”œâ”€â”€ agents/             # RL algorithm implementations
â”œâ”€â”€ environments/       # Custom wrappers and environment configurations
â”œâ”€â”€ training/           # Training scripts for each agent/environment
â”œâ”€â”€ evaluation/         # Evaluation scripts and comparative analysis
â”œâ”€â”€ results/            # Training logs, reward curves, and saved models
â”œâ”€â”€ notebooks/          # Jupyter notebooks for analysis and plotting
â”œâ”€â”€ config/             # YAML configuration files
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ report.pdf          # Final project report
â””â”€â”€ README.md           # This file
```

---

## âš™ï¸ Installation

1. Clone this repository:

```bash
git clone https://github.com/TiagoPedrotkd/RL_GP.git
cd RL_GP
```

2. *(Optional)* Create and activate a virtual environment:

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install required packages:

```bash
pip install -r requirements.txt
```

---

## ðŸš€ How to Run

### Train Agent on Environment 1:

```bash
python training/train_env1.py
```

### Evaluate Agent on Environment 1:

```bash
python evaluation/evaluate_env1.py
```

> Training metrics and visualizations will be saved in the `results/` directory.

---

## ðŸ“Š Visualizations

- Total reward per episode
- Moving average of rewards
- Convergence curves
- Performance comparison across agents

> Visual outputs and further analysis can be found in the `notebooks/` folder.

---

## ðŸ“˜ Report

A detailed description of the methodology, evaluation metrics, challenges, and results is available in [`report.pdf`](./report.pdf).

---

## ðŸ‘¥ Authors

Developed by:

- Name 1 (email)
- Name 2 (email)
- Name 3 (email)

---

## ðŸ“„ License

This project is for educational purposes only. All rights reserved by the authors.
